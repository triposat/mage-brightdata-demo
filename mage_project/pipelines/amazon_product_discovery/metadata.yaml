blocks:
# 1. DATA LOADER: Fetch products from Bright Data
- all_upstream_blocks_executed: true
  color: null
  configuration:
    file_path: data_loaders/amazon_product_discovery.py
  downstream_blocks:
  - process_amazon_products
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: amazon_product_discovery
  retry_config: null
  status: executed
  timeout: null
  type: data_loader
  upstream_blocks: []
  uuid: amazon_product_discovery

# 2. TRANSFORMER: Clean and enrich data
- all_upstream_blocks_executed: true
  color: null
  configuration:
    file_path: transformers/process_amazon_products.py
  downstream_blocks:
  - detect_price_changes
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: process_amazon_products
  retry_config: null
  status: executed
  timeout: null
  type: transformer
  upstream_blocks:
  - amazon_product_discovery
  uuid: process_amazon_products

# 3. TRANSFORMER: Detect price changes vs historical data
- all_upstream_blocks_executed: true
  color: null
  configuration:
    file_path: transformers/detect_price_changes.py
  downstream_blocks:
  - check_data_quality
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: detect_price_changes
  retry_config: null
  status: not_executed
  timeout: null
  type: transformer
  upstream_blocks:
  - process_amazon_products
  uuid: detect_price_changes

# 4. CONDITIONAL: Check data quality before export
- all_upstream_blocks_executed: true
  color: null
  configuration:
    file_path: conditionals/check_data_quality.py
  downstream_blocks:
  - export_amazon_to_postgres
  - export_amazon_to_csv
  - export_alerts
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: check_data_quality
  retry_config: null
  status: not_executed
  timeout: null
  type: conditional
  upstream_blocks:
  - detect_price_changes
  uuid: check_data_quality

# 5. EXPORTER: Save to PostgreSQL
- all_upstream_blocks_executed: true
  color: null
  configuration:
    file_path: data_exporters/export_amazon_to_postgres.py
  downstream_blocks: []
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: export_amazon_to_postgres
  retry_config: null
  status: not_executed
  timeout: null
  type: data_exporter
  upstream_blocks:
  - check_data_quality
  uuid: export_amazon_to_postgres

# 6. EXPORTER: Save to CSV
- all_upstream_blocks_executed: true
  color: null
  configuration:
    file_path: data_exporters/export_amazon_to_csv.py
  downstream_blocks: []
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: export_amazon_to_csv
  retry_config: null
  status: not_executed
  timeout: null
  type: data_exporter
  upstream_blocks:
  - check_data_quality
  uuid: export_amazon_to_csv

# 7. EXPORTER: Send alerts for price changes
- all_upstream_blocks_executed: true
  color: null
  configuration:
    file_path: data_exporters/export_alerts.py
  downstream_blocks: []
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: export_alerts
  retry_config: null
  status: not_executed
  timeout: null
  type: data_exporter
  upstream_blocks:
  - check_data_quality
  uuid: export_alerts

# Pipeline settings
cache_block_output_in_memory: false
callbacks: []
concurrency_config: {}
conditionals:
- check_data_quality
created_at: '2026-02-09 11:48:06.240011+00:00'
data_integration: null
description: |
  Amazon Product Discovery Pipeline

  This pipeline demonstrates enterprise-grade web scraping by:
  1. Fetching products from Bright Data's Amazon API
  2. Cleaning and enriching the data
  3. Detecting price changes vs historical data
  4. Validating data quality before export
  5. Exporting to PostgreSQL and CSV
  6. Sending alerts for significant price changes

  Features used:
  - Bright Data Web Scraper API
  - Mage AI conditionals (data quality gates)
  - Mage AI transformers (price change detection)
  - Multiple export destinations
  - Configurable pipeline variables
executor_config: {}
executor_count: 1
executor_type: null
extensions: {}
name: amazon_product_discovery
notification_config: {}
remote_variables_dir: null
retry_config: {}
run_pipeline_in_one_process: false
settings:
  triggers: null
spark_config: {}
tags:
- brightdata
- amazon
- price-tracking
- web-scraping
type: python
uuid: amazon_product_discovery
variables:
  # Search keywords - easily configurable!
  keywords:
  - laptop stand
  - mechanical keyboard
  - monitor light

  # Products per keyword
  limit_per_keyword: 25

  # Price change threshold for alerts (percentage)
  price_change_threshold: 10

  # Data quality thresholds
  min_products: 10
  min_price_rate: 0.5
  min_rating_rate: 0.5

  # Alert settings
  alert_on_any_change: false

variables_dir: /home/src/mage_project
widgets: []
